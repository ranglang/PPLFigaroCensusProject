Bayseian Probability

Probability distribution - assigns num between 0 and 1 to every possible world. A possible world consists of a value for each variable

VariableElimination: "a simple and general exact inference algorithm in probabilistic graphical models, such as Bayesian networks and Markov random fields" (Wikipedia). EXACT INFERENCE

MH: "Metropolisâ€“Hastings algorithm is a Markov chain Monte Carlo (MCMC) method for obtaining a sequence of random samples from a probability distribution for which direct sampling is difficult." (Wikipedia)

Importance: "general technique for estimating properties of a particular distribution, while only having samples generated from a different distribution than the distribution of interest. It is related to umbrella sampling in computational physics" (Wikipedia)
Good if expanding a model produces an infinite number of elements or if you have atomic continuous
models.

CPD = Conditional Probability Distribution
RichCPD = better if you have multiple parents
CPD describes its dependency on the values of its parents (Bayseian?)

Density - built into Figaro (PDF - Probability Density Function). Functional form of a continuous variable specified by a PDF

=================================================
=================================================

There are Two Main Types of Inference Algorithms:
1. Factored Algorithms: operate on data structures called factors that capture the probabilistic model being reasoned about
2. Sampling Algorithms: create examples of possible worlds from the probability distribution and using those examples to answer queries 

   ****FACTORED INFERENCE ALGORITHMS****

   - Factor: representation of a function from the value of a set of variables to a real number. Why are factors useful? 
   - Probability distributions are functions that, given a value for each variable in the model, assigns a number between 0 and 1. Distribution can be represented by a factor. Probability Distribution represented as a table 
   - Joint Probability Distribution

  +---------------------------+
  |VARIABLE ELIMINATION (VE)  |
  +---------------------------+
	> Exact Algorithm - computes exact probability of query, given the evidence as defined in the model. Exact but slow
 	> One at a time, eliminate the nonquery variables from the expression by using simple algebra
 	> Graph inducing! Marrying the graph and cliques 
 	> Is this NPC hehehe
 	> Triangulated graph (all loops in the graph are made up of triangles). If the graph is triangulated, the factors you produce during inference won't be any larger than the factors you started with
 	> Eliminate(V, S) {
  		Move all factors in S that mention V to the right
  		Move the summation over V so that it encloses only those factors
  		Compute the inner sum-of-products involving the factors that mention V
  		Replace this sum-of-products in S with the resulting factor
	  }
	> VariableElimination(S) {
  		Choose an elimination order O that contains all variables except the query variables
  			For each variable V in O {
    		Eliminate(V, S)
  		}
	  }
	> In Figaro, VE run by passing list of query targets to VE Constructor to create an algorithm, and then querying it after
	> VE basically turns probabilistic program into a giant Bayesian network
	>>>>> The number of variables that could possibly exist in this model are FINITE. Needs an Upper-Bound (can't use recursive models)
	> Size of the factor is exponential in the number of parents..... try and minimize the number of parents!
	> Useful to use VE if you can eliminate variables without adding too many edges to VE graph (size of largest clique in VE graph small)
	> Used for speech recognition and natural language understanding (parsing a sentence)


  +------------------------+
  |BELIEF PROPOGATION (BP) |
  +------------------------+
	> Approximation Algorithm - fast, most of the time returns an answer that is close to the right answer but not always 
	> Tradeoffs in accuracy and speed between BP and VE
	> Exponentially faster inference than VE. Doesn't add edges necessary for correct inference, so will not be as accurate.
	> BP performs calculations for queries on all variables in network simultaenously. After you run BP, you can get posterior probability of any variable, given the evidence
	> The more iterations of BP you run the more accurate. Figaro uses asynchronous form of BP. 
	> Avoid too many loops (too many loops means more potential for error). Merge elements together (to avoid loop). Decompose CPDs with lots of parents. Simplify the network
	> Applications of BP - any model with discrete variables. Image analysis. Medical diagnosis (symptoms). Building, vehicle, or equpiment health monitoring




	****SAMPLING ALGORITHMS****

   - Sampling Algorithms: answer queries by generating possible states of variables drawn from the probability distribution defined by the program
   - Sampling Algo vs. Factoring Algo: Rather than representing probability distribution over possible worlds as a set of numbers, use a set of examples of possible worlds (samples)
   - Rather than computing "true" distribution directly, generate a set of samples. Each sample is a possible world. Probability of generating a particular possible world should be equal to probability of that possible world
   - There is a true distribution you want to compute. You generate samples drawn from this true distribution. You esitmate the distribution by using these samples
   - Sampling works for continuous variables!
   - Sampling is MOST useful for continuous (infinitely many) variables. Continuous variables use a probability density function

   2 main kinds of sampling algorithms:
   1. Forward Sampling (Importance) : straightforward; directly generate a sample from desired distribution by running the probabilistic program. 
   2. Markov chain Monte Carlo (MCMC) : rather than sampling from a distribution directly, define a sampling process that eventually converges to the true distribution


   +-----------------------+
   |||<Forward Sampling>|| |
   +-----------------------+
   > Forward sampling: generate values for the variables in a probabilistic program one at a time. Generate a value for all the variables, and you have a possible world (this constitues a single sample)
   		~ Forward sampling generates samples from prior probability distribution
   > Variable's definition defines a probability distribution over this variable. Value for variable chosen according to the distribution. 
   > Topological order: always generate values for parents for variable before generating value for the variable
   > Probability of a possible world is estimated to be the fraction of samples equal to that word
   > Sampling is only one representation of a probability distribution over the possible worlds. 
   > Forward sampling: randomized proccess - gets different result every time. 
   > Why use sampling? When using many variables with rich data types with infinitely many values. You need to consider a relatively small number of possibilities and you get an estimate of the probability distribution you're seeking
   > Sampling computes only a finite fraction of the tree (if it is infinite) and uses it to estimate the distribution
   > On average, sample distribution will be equal to true distribution ("unbiased"). The more samples you use, the closer you expect the sample distribution to be to the true distribution ("the variance of the sampling process decreases with more samples")
   > Why sampling algorithms are so appealing: you can get as close as you want to the true distribution if you use enough samples, and it's easy to answer queries by using the samples


   +------------------------+
   |||<Rejection Sampling>|||
   +------------------------+
   > Forward sampling doesn't consider evidence in the form of conditions or constraints. Without evidence, program defines prior distribution over possible worlds
   > We need a way of generating samples from posterior distribution! (obtained after conditioning on the evidence). Do this using REJECTION SAMPLING
   > Rejection sampling - use forward sampling as before, but reject any samples that disagree with the evidence
   > Start with prior distribution over possible worlds. When you observe evidence, "cross out" worlds that disagree with the evidence and assign them zero probability. Normalize resulting probabilities to get posterior distribution.
   		~ It's not an efficient use of memory to store samples that are eventually going to be rejected
   		~ It's not necessary to generate an entire sample before checking whether it's consistent with the evidence 
   		~ Significant time savings (vs waiting to reject until after the full sample has been generated)
   > Pros: samples that aren't rejected are drawn from posterior distribution. The more samples, the closer to sample distribution.
   > Cons: Vast majority of samples could be rejected. i.e. if evidence has low probability, the vast majority of samples will be rejected
   > The amount of work you have to do to generate a good sample set when using rejection sampling grows exponentially with the number of evidence variables
   > Lol rejection sampling generally not considered to be a practical algorithm



   +--------------------+
   |Importance Sampling |
   +--------------------+
   > Similar to rejection sampling but can handle constraints. In the right circumstances, importance sampling can avoid rejecting with conditions by turning the conditions into constraints on other variables
   > Hard condition - a property that a value must ssatisfy to have a positive probability (multiply probability by 0 if the value of the element doesn't satisfy the condition, and by 1 if it does satisfy the condition)
   > Soft constraint - 
   > Importance sampling uses weighted samples 
   > Use if: model has continuous variables, or has a variable structure (parts of model exist for only particular values of other variables)
   > Applications: prediction via simulation (when you have no evidence at all - no conditions or constraints in the program)



   +--------------------------------+
   |Markov chain Monte Carlo (MCMC) |
   +--------------------------------+
   > Start each step of algorithm where the previous sample left off
   > MCMC can more quickly get to samples that have high probability


   +-------------------------+
   |Metropolis-Hastings (MH) |
   +-------------------------+
   > Figaro's MCMC algorithm: Metropolis-Hastings
   > Default Proposal scheme:
   		1. Choose a single nondeterministic element at random. i.e. Flip
   		2. Propose a new value for the chosen element
   		3. Update the vlaues of elements that depend on this chosen element
   > MetropolisHastings(1000, ProposalScheme.default, x, y)
   		use default proposal scheme to obtain approximate posterior distributions for x and 
   > Rather than sampling a new state at every iteration, the sampling process guides the algo to sampling high-probability states





Expectation Maximization (Ch 12)
- goal: to learn a specific set of parameter values from data
- Iterative method for finding maximum likelihood or finding Maximum a posteriori (MAP) estimates of parameters in statistical models (Wikipedia)
- EM iteration alternates between performing an expectation (E) step, which creates a fxn for the expectation of the log-likelihood evaluated using the current estimate for the parameters, and a maximization (M) step, which computes parameters maximizing the expected log-likelihood found on the E step. These parameter-estimates are then used to determine the distribution of the latent variables in the next E step
- Iteratively guesses a distribution for the unobserved data




We will have a probabilistic model using discrete variables (not continuous)


